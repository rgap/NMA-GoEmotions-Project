{"cells":[{"cell_type":"markdown","metadata":{"id":"hgA4zWpOOA5D"},"source":["## Data Collection and Feature Engineering steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVcsYdSqPja9"},"outputs":[],"source":["from IPython.display import clear_output\n","!pip install transformers[torch]\n","clear_output()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47475,"status":"ok","timestamp":1721940354320,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"_0H-B2c-OA5F","outputId":"6e8f2ad2-976e-4d57-80e5-0f7c25466075"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","X_train shape: torch.Size([32798, 316])\n","y_train shape: torch.Size([32798])\n","y_train unique: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from transformers import BertTokenizer\n","\n","def load_data(data_url):\n","    return pd.read_csv(data_url, sep='\\t')\n","\n","def preprocess_data(data):\n","    header = [\"comment\", \"emotion\", \"id\"]\n","    data.columns = header\n","    data = data[['comment', 'emotion']]\n","    data = data[data['emotion'].apply(lambda x: len(x.split(',')) == 1)]\n","    data['emotion'] = data['emotion'].apply(lambda x: ''.join(filter(str.isdigit, str(x)))).astype(int)\n","    return data\n","\n","def remove_emotions(data, emotions_to_remove):\n","    data = data[~data['emotion'].isin(emotions_to_remove)].copy()\n","    unique_emotions = sorted(data['emotion'].unique())\n","    label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_emotions)}\n","    data.loc[:, 'emotion'] = data['emotion'].map(label_mapping)\n","    return data, label_mapping\n","\n","def sample_data(data, fraction=1.0):\n","    return data.groupby('emotion', group_keys=False).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)\n","\n","def tokenize_data(comments):\n","    # Tokenize using the BERT tokenizer\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    return tokenizer(comments, padding=True, truncation=True, return_tensors='pt')\n","\n","# URLs for train and validation data\n","train_data_url = 'https://github.com/google-research/google-research/raw/master/goemotions/data/train.tsv'\n","validation_data_url = 'https://github.com/google-research/google-research/raw/master/goemotions/data/dev.tsv'\n","\n","# Process train data\n","train_data = load_data(train_data_url)\n","train_data = preprocess_data(train_data)\n","train_data, _ = remove_emotions(train_data, emotions_to_remove=[1, 15])\n","sampled_train_data = sample_data(train_data)\n","\n","# Process validation data\n","validation_data = load_data(validation_data_url)\n","validation_data = preprocess_data(validation_data)\n","sampled_validation_data = sample_data(validation_data)\n","\n","# Tokenize the comments\n","train_tokenized_comments = tokenize_data(sampled_train_data['comment'].to_list())\n","validation_tokenized_comments = tokenize_data(sampled_validation_data['comment'].to_list())\n","\n","# Prepare training data\n","X_train = train_tokenized_comments['input_ids']\n","attention_masks_train = train_tokenized_comments['attention_mask']\n","y_train = torch.tensor(sampled_train_data['emotion'].values)\n","\n","# Prepare validation data\n","X_validation = validation_tokenized_comments['input_ids']\n","attention_masks_validation = validation_tokenized_comments['attention_mask']\n","y_validation = torch.tensor(sampled_validation_data['emotion'].values)\n","\n","# Map the new labels to their original emotion names\n","emotions_dict = {\n","    0: \"admiration\", 1: \"amusement\", 2: \"anger\", 3: \"annoyance\", 4: \"approval\",\n","    5: \"caring\", 6: \"confusion\", 7: \"curiosity\", 8: \"desire\", 9: \"disappointment\",\n","    10: \"disapproval\", 11: \"disgust\", 12: \"embarrassment\", 13: \"excitement\", 14: \"fear\",\n","    15: \"gratitude\", 16: \"grief\", 17: \"joy\", 18: \"love\", 19: \"nervousness\",\n","    20: \"optimism\", 21: \"pride\", 22: \"realization\", 23: \"relief\", 24: \"remorse\",\n","    25: \"sadness\", 26: \"surprise\", 27: \"neutral\"\n","}\n","\n","print()\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_train unique:\", np.unique(y_train))"]},{"cell_type":"markdown","metadata":{"id":"51iwH5DzOA5H"},"source":["# 1. Model Building\n","\n","Here's the current research question:\n","\n","**\"Can we predict the sentiment of a textual comment?\"**"]},{"cell_type":"markdown","metadata":{"id":"OmwvMxinOA5H"},"source":["### Initialization"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1721940354320,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"HlSyok5zOA5H","outputId":"82bc1c16-339a-4548-ddb7-58a66dec74a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: mps\n","MPS memory allocated: 0.00 GB\n"]}],"source":["def get_device():\n","    if torch.cuda.is_available():\n","        return torch.device(\"cuda\")\n","    if torch.backends.mps.is_available():\n","        return torch.device(\"mps\")\n","    return torch.device(\"cpu\")\n","\n","def print_device_info(device):\n","    print(f\"Using device: {device}\")\n","    if device.type == \"cuda\":\n","        print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n","        print(f\"CUDA memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n","    elif device.type == \"mps\":\n","        torch.mps.empty_cache()\n","        print(f\"MPS memory allocated: {torch.mps.current_allocated_memory() / 1e9:.2f} GB\")\n","    elif device.type == \"cpu\":\n","        print(\"No GPU available. Using CPU.\")\n","\n","device = get_device()\n","print_device_info(device)"]},{"cell_type":"markdown","metadata":{"id":"LwXME0NuOA5H"},"source":["### Define the model"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4356,"status":"ok","timestamp":1721940358671,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"9WVVrFlVOA5H","outputId":"e266cc35-b8d8-47f6-afc2-f4f485b205a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForSequenceClassification\n","# Load the BERT model\n","# we will use the bert-base-uncased model\n","# this model will classify the comments into 10 emotions\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=28)\n","model.to(device);  # Move the model to the GPU"]},{"cell_type":"markdown","metadata":{"id":"XNG5tEjbOA5H"},"source":["### Defining the emotion dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1874096,"status":"ok","timestamp":1721942232762,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"FwN2O_FBOA5H","outputId":"67bf2cb4-cb32-4654-fdf2-2b31c698cf31"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/training_args.py:1540: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a59136b17bfe410f8a421feda338d372","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1536 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from torch.utils.data import Dataset\n","from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n","\n","\n","# Create a Dataset class\n","class EmotionDataset(Dataset):\n","    def __init__(self, input_ids, attention_masks, labels):\n","        self.input_ids = input_ids\n","        self.attention_masks = attention_masks\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_ids[idx],\n","            'attention_mask': self.attention_masks[idx],\n","            'labels': self.labels[idx]\n","        }\n","\n","# Prepare datasets\n","train_dataset = EmotionDataset(X_train, attention_masks_train, y_train)\n","validation_dataset = EmotionDataset(X_validation, attention_masks_validation, y_validation)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',  # Directory to save the model checkpoints\n","    num_train_epochs=3,  # Total number of training epochs\n","    per_device_train_batch_size=32,  # Batch size per device during training\n","    per_device_eval_batch_size=32,  # Batch size for evaluation\n","    warmup_steps=50,  # Number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,  # Strength of weight decay\n","    logging_dir='./logs',  # Directory for storing logs\n","    logging_steps=10,  # Log every X updates steps\n","    evaluation_strategy=\"steps\",  # Evaluate the model every X steps\n","    save_strategy=\"steps\",  # Save the model checkpoint every X steps\n","    save_steps=0,  # Steps interval for saving model checkpoint (We dont need to save steps)\n","    eval_steps=10,  # Steps interval for evaluation\n","    gradient_accumulation_steps=2,  # Number of updates steps to accumulate before performing a backward/update pass\n","    fp16=True,  # Use 16-bit (mixed) precision training\n","    learning_rate=3e-5,  # The initial learning rate for AdamW optimizer\n","    load_best_model_at_end=True,  # Load the best model when finished training (default metric is loss)\n","    lr_scheduler_type=\"reduce_lr_on_plateau\",  # Learning rate scheduler type\n","    metric_for_best_model=\"eval_loss\",  # Use loss to identify the best model\n","    save_total_limit=2,  # Limit the total amount of checkpoints. Deletes the older checkpoints.\n","    greater_is_better=False,  # Set to True if the metric to optimize is greater (e.g. Accuracy, F1). False for metrics which are lower (e.g. loss)\n","    no_cuda=True if device.type != 'cuda' else False,  # Do not use CUDA even when available\n",")\n","\n","# Initialize Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",")\n","\n","# Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":449,"status":"ok","timestamp":1721942233202,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"tGwXHQx2OA5I","outputId":"a806fbfb-e8ce-4127-be38-1cbd4a2fadd7"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","\n","# # Extract loss values from the logs\n","# train_losses = []\n","# eval_losses = []\n","# for log in trainer.state.log_history:\n","#     if 'loss' in log:\n","#         train_losses.append(log['loss'])\n","#     if 'eval_loss' in log:\n","#         eval_losses.append(log['eval_loss'])\n","\n","# # Plot the losses\n","# plt.plot(train_losses, label='Training Loss')\n","# plt.plot(eval_losses, label='Validation Loss')\n","# plt.xlabel('Logging Steps')\n","# plt.ylabel('Loss')\n","# plt.title('Training and Validation Loss')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"r4f4V5i4ciXt"},"source":["### Save Model (only from google drive)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28474,"status":"ok","timestamp":1721942734333,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"8iuldGita6IC","outputId":"9e03c364-20a4-463e-b476-4d71216cc22d"},"outputs":[],"source":["# # Mount Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":485,"status":"ok","timestamp":1721942737966,"user":{"displayName":"Nolan Eduardo Casas","userId":"15662852858614813971"},"user_tz":300},"id":"cGJJ54qDbWEt","outputId":"7057beb4-3339-4a9c-b8fb-29c9e7712b75"},"outputs":[],"source":["# import os\n","\n","# project_name = \"NMA-GoEmotions-Project\"\n","# model_save_path = f'/content/drive/MyDrive/@NMA_Projects/{project_name}/{project_name}/model'\n","\n","# source_path = './results/'\n","\n","# # Create the destination directory if it doesn't exist\n","# os.makedirs(model_save_path, exist_ok=True)\n","\n","# # Save only the classification layer weights\n","# classifier_weights = model.classifier.state_dict()\n","# torch.save(classifier_weights, os.path.join(model_save_path, 'classifier_weights_bert.pt'))\n","\n","# print(f\"Model copied to Google Drive at: {model_save_path}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
