{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Feature Engineering steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xd/gw_pmm5d23s8dm3h09tn28x00000gn/T/ipykernel_16146/1362815814.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return data.groupby('emotion', group_keys=False).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)\n",
      "/var/folders/xd/gw_pmm5d23s8dm3h09tn28x00000gn/T/ipykernel_16146/1362815814.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return data.groupby('emotion', group_keys=False).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 2 most common emotions: ['neutral', 'admiration']\n",
      "Sampled train data shape: (1553, 2)\n",
      "Sampled validation data shape: (192, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def load_data(data_url):\n",
    "    return pd.read_csv(data_url, sep='\\t')\n",
    "\n",
    "def preprocess_data(data):\n",
    "    header = [\"comment\", \"emotion\", \"id\"]\n",
    "    data.columns = header\n",
    "    data = data[['comment', 'emotion']]\n",
    "    data = data[data['emotion'].apply(lambda x: len(x.split(',')) == 1)]\n",
    "    data['emotion'] = data['emotion'].apply(lambda x: ''.join(filter(str.isdigit, str(x)))).astype(int)\n",
    "    return data\n",
    "\n",
    "def filter_top_emotions(data, top_n=2):\n",
    "    emotion_counts = data['emotion'].value_counts()\n",
    "    top_emotions = emotion_counts.head(top_n).index\n",
    "    label_mapping = {label: new_label for new_label, label in enumerate(top_emotions)}\n",
    "    filtered_data = data[data['emotion'].isin(top_emotions)].copy()\n",
    "    filtered_data.loc[:, 'emotion'] = filtered_data['emotion'].map(label_mapping)\n",
    "    return filtered_data, label_mapping\n",
    "\n",
    "def sample_data(data, fraction=0.1):\n",
    "    return data.groupby('emotion', group_keys=False).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)\n",
    "\n",
    "def tokenize_data(comments):\n",
    "    # Tokenize using the BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    return tokenizer(comments, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# URLs for train and validation data\n",
    "train_data_url = 'https://raw.githubusercontent.com/google-research/google-research/master/goemotions/data/train.tsv'\n",
    "validation_data_url = 'https://github.com/google-research/google-research/raw/master/goemotions/data/dev.tsv'\n",
    "\n",
    "# Process train data\n",
    "train_data = load_data(train_data_url)\n",
    "train_data = preprocess_data(train_data)\n",
    "sampled_train_data, label_mapping = filter_top_emotions(train_data)\n",
    "sampled_train_data = sample_data(sampled_train_data)\n",
    "\n",
    "# Process validation data\n",
    "validation_data = load_data(validation_data_url)\n",
    "validation_data = preprocess_data(validation_data)\n",
    "sampled_validation_data, _ = filter_top_emotions(validation_data, top_n=len(label_mapping))\n",
    "sampled_validation_data = sample_data(sampled_validation_data)\n",
    "\n",
    "# Tokenize the comments\n",
    "train_tokenized_comments = tokenize_data(sampled_train_data['comment'].to_list())\n",
    "validation_tokenized_comments = tokenize_data(sampled_validation_data['comment'].to_list())\n",
    "\n",
    "# Prepare training data\n",
    "X_train = train_tokenized_comments['input_ids']\n",
    "attention_masks_train = train_tokenized_comments['attention_mask']\n",
    "y_train = torch.tensor(sampled_train_data['emotion'].values)\n",
    "\n",
    "# Prepare validation data\n",
    "X_validation = validation_tokenized_comments['input_ids']\n",
    "attention_masks_validation = validation_tokenized_comments['attention_mask']\n",
    "y_validation = torch.tensor(sampled_validation_data['emotion'].values)\n",
    "\n",
    "# Map the new labels to their original emotion names\n",
    "emotions_dict = {\n",
    "    0: \"admiration\", 1: \"amusement\", 2: \"anger\", 3: \"annoyance\", 4: \"approval\",\n",
    "    5: \"caring\", 6: \"confusion\", 7: \"curiosity\", 8: \"desire\", 9: \"disappointment\",\n",
    "    10: \"disapproval\", 11: \"disgust\", 12: \"embarrassment\", 13: \"excitement\", 14: \"fear\",\n",
    "    15: \"gratitude\", 16: \"grief\", 17: \"joy\", 18: \"love\", 19: \"nervousness\",\n",
    "    20: \"optimism\", 21: \"pride\", 22: \"realization\", 23: \"relief\", 24: \"remorse\",\n",
    "    25: \"sadness\", 26: \"surprise\", 27: \"neutral\"\n",
    "}\n",
    "top_emotions_dict = {label_mapping[k]: emotions_dict[k] for k in label_mapping}\n",
    "\n",
    "print()\n",
    "print(\"Top 2 most common emotions:\", [top_emotions_dict[e] for e in sorted(top_emotions_dict)])\n",
    "print(\"Sampled train data shape:\", sampled_train_data.shape)\n",
    "print(\"Sampled validation data shape:\", sampled_validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Building - ML Classifiers\n",
    "\n",
    "We try classic ML Classifiers first.\n",
    "\n",
    "Here's the current research question:\n",
    "\n",
    "**\"Can we predict the sentiment of a textual comment?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "MPS memory allocated: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def print_device_info(device):\n",
    "    print(f\"Using device: {device}\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"CUDA memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    elif device.type == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "        print(f\"MPS memory allocated: {torch.mps.current_allocated_memory() / 1e9:.2f} GB\")\n",
    "    elif device.type == \"cpu\":\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "              \n",
    "device = get_device()\n",
    "print_device_info(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "# Load the BERT model\n",
    "# we will use the bert-base-uncased model\n",
    "# this model will classify the comments into 10 emotions\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device);  # Move the model to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the emotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9246d641cba453fb70d0f1fe6cc5e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 55\u001b[0m\n\u001b[1;32m     47\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     48\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     49\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     50\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     51\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mvalidation_dataset\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/trainer.py:3307\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3307\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3311\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/trainer.py:3338\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3337\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3338\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3340\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1695\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1695\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1709\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/testk/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    437\u001b[0m )\n\u001b[0;32m--> 439\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"ACCELERATE_USE_MPS_DEVICE\"] = \"True\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "# Create a Dataset class\n",
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = EmotionDataset(X_train, attention_masks_train, y_train)\n",
    "validation_dataset = EmotionDataset(X_validation, attention_masks_validation, y_validation)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",  # Evaluate every few steps\n",
    "    eval_steps=10,  # Evaluate every 10 logging steps\n",
    "    no_cuda=True if device != 'cuda' else False,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.960740327835083, 'eval_runtime': 1.798, 'eval_samples_per_second': 106.788, 'eval_steps_per_second': 6.674, 'epoch': 0.10204081632653061, 'step': 10}\n",
      "{'eval_loss': 0.8378753066062927, 'eval_runtime': 1.8162, 'eval_samples_per_second': 105.718, 'eval_steps_per_second': 6.607, 'epoch': 0.20408163265306123, 'step': 20}\n",
      "{'eval_loss': 0.6794535517692566, 'eval_runtime': 1.7988, 'eval_samples_per_second': 106.737, 'eval_steps_per_second': 6.671, 'epoch': 0.30612244897959184, 'step': 30}\n",
      "{'eval_loss': 0.5730319619178772, 'eval_runtime': 1.8407, 'eval_samples_per_second': 104.311, 'eval_steps_per_second': 6.519, 'epoch': 0.40816326530612246, 'step': 40}\n",
      "{'eval_loss': 0.5262773633003235, 'eval_runtime': 1.8506, 'eval_samples_per_second': 103.752, 'eval_steps_per_second': 6.484, 'epoch': 0.5102040816326531, 'step': 50}\n",
      "{'eval_loss': 0.492962121963501, 'eval_runtime': 1.8648, 'eval_samples_per_second': 102.962, 'eval_steps_per_second': 6.435, 'epoch': 0.6122448979591837, 'step': 60}\n",
      "{'eval_loss': 0.46758031845092773, 'eval_runtime': 1.8293, 'eval_samples_per_second': 104.958, 'eval_steps_per_second': 6.56, 'epoch': 0.7142857142857143, 'step': 70}\n",
      "{'eval_loss': 0.45463529229164124, 'eval_runtime': 1.8569, 'eval_samples_per_second': 103.399, 'eval_steps_per_second': 6.462, 'epoch': 0.8163265306122449, 'step': 80}\n",
      "{'eval_loss': 0.4526638686656952, 'eval_runtime': 1.8565, 'eval_samples_per_second': 103.421, 'eval_steps_per_second': 6.464, 'epoch': 0.9183673469387755, 'step': 90}\n",
      "{'loss': 0.6137, 'grad_norm': 3.680121660232544, 'learning_rate': 1e-05, 'epoch': 1.0204081632653061, 'step': 100}\n",
      "{'eval_loss': 0.4520460069179535, 'eval_runtime': 1.8747, 'eval_samples_per_second': 102.418, 'eval_steps_per_second': 6.401, 'epoch': 1.0204081632653061, 'step': 100}\n",
      "{'eval_loss': 0.41237786412239075, 'eval_runtime': 1.8471, 'eval_samples_per_second': 103.945, 'eval_steps_per_second': 6.497, 'epoch': 1.1224489795918366, 'step': 110}\n",
      "{'eval_loss': 0.33985695242881775, 'eval_runtime': 1.8486, 'eval_samples_per_second': 103.861, 'eval_steps_per_second': 6.491, 'epoch': 1.2244897959183674, 'step': 120}\n",
      "{'eval_loss': 0.2666667401790619, 'eval_runtime': 1.8732, 'eval_samples_per_second': 102.5, 'eval_steps_per_second': 6.406, 'epoch': 1.3265306122448979, 'step': 130}\n",
      "{'eval_loss': 0.22643138468265533, 'eval_runtime': 1.8782, 'eval_samples_per_second': 102.228, 'eval_steps_per_second': 6.389, 'epoch': 1.4285714285714286, 'step': 140}\n",
      "{'eval_loss': 0.18879954516887665, 'eval_runtime': 1.8341, 'eval_samples_per_second': 104.681, 'eval_steps_per_second': 6.543, 'epoch': 1.5306122448979593, 'step': 150}\n",
      "{'eval_loss': 0.18005619943141937, 'eval_runtime': 1.9554, 'eval_samples_per_second': 98.191, 'eval_steps_per_second': 6.137, 'epoch': 1.6326530612244898, 'step': 160}\n",
      "{'eval_loss': 0.17179405689239502, 'eval_runtime': 1.9037, 'eval_samples_per_second': 100.857, 'eval_steps_per_second': 6.304, 'epoch': 1.7346938775510203, 'step': 170}\n",
      "{'eval_loss': 0.19554562866687775, 'eval_runtime': 1.8398, 'eval_samples_per_second': 104.36, 'eval_steps_per_second': 6.522, 'epoch': 1.836734693877551, 'step': 180}\n",
      "{'eval_loss': 0.23888294398784637, 'eval_runtime': 1.8212, 'eval_samples_per_second': 105.426, 'eval_steps_per_second': 6.589, 'epoch': 1.9387755102040818, 'step': 190}\n",
      "{'loss': 0.2771, 'grad_norm': 0.915139377117157, 'learning_rate': 2e-05, 'epoch': 2.0408163265306123, 'step': 200}\n",
      "{'eval_loss': 0.1685391664505005, 'eval_runtime': 1.9217, 'eval_samples_per_second': 99.911, 'eval_steps_per_second': 6.244, 'epoch': 2.0408163265306123, 'step': 200}\n",
      "{'eval_loss': 0.18401741981506348, 'eval_runtime': 1.967, 'eval_samples_per_second': 97.61, 'eval_steps_per_second': 6.101, 'epoch': 2.142857142857143, 'step': 210}\n",
      "{'eval_loss': 0.28628528118133545, 'eval_runtime': 1.8943, 'eval_samples_per_second': 101.359, 'eval_steps_per_second': 6.335, 'epoch': 2.2448979591836733, 'step': 220}\n",
      "{'eval_loss': 0.2359790802001953, 'eval_runtime': 1.8815, 'eval_samples_per_second': 102.044, 'eval_steps_per_second': 6.378, 'epoch': 2.3469387755102042, 'step': 230}\n",
      "{'eval_loss': 0.23568713665008545, 'eval_runtime': 1.8638, 'eval_samples_per_second': 103.014, 'eval_steps_per_second': 6.438, 'epoch': 2.4489795918367347, 'step': 240}\n",
      "{'eval_loss': 0.3978496491909027, 'eval_runtime': 1.8725, 'eval_samples_per_second': 102.537, 'eval_steps_per_second': 6.409, 'epoch': 2.5510204081632653, 'step': 250}\n",
      "{'eval_loss': 0.22042329609394073, 'eval_runtime': 1.8524, 'eval_samples_per_second': 103.647, 'eval_steps_per_second': 6.478, 'epoch': 2.6530612244897958, 'step': 260}\n",
      "{'eval_loss': 0.2589400112628937, 'eval_runtime': 1.9069, 'eval_samples_per_second': 100.689, 'eval_steps_per_second': 6.293, 'epoch': 2.7551020408163263, 'step': 270}\n",
      "{'eval_loss': 0.2013065367937088, 'eval_runtime': 1.9259, 'eval_samples_per_second': 99.692, 'eval_steps_per_second': 6.231, 'epoch': 2.857142857142857, 'step': 280}\n",
      "{'eval_loss': 0.1800512820482254, 'eval_runtime': 1.8753, 'eval_samples_per_second': 102.382, 'eval_steps_per_second': 6.399, 'epoch': 2.9591836734693877, 'step': 290}\n",
      "{'train_runtime': 236.6532, 'train_samples_per_second': 19.687, 'train_steps_per_second': 1.242, 'total_flos': 105345144344880.0, 'train_loss': 0.35321516568968897, 'epoch': 3.0, 'step': 294}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract loss values from the logs\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "for log in trainer.state.log_history:\n",
    "    print(log)\n",
    "    if 'loss' in log:\n",
    "        train_losses.append(log['loss'])\n",
    "    if 'eval_loss' in log:\n",
    "        eval_losses.append(log['eval_loss'])\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(eval_losses, label='Validation Loss')\n",
    "plt.xlabel('Logging Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
